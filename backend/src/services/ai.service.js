import { GoogleGenerativeAI } from '@google/generative-ai';
import { AI_CONFIG, MITA_PERSONALITY } from '../config/ai.config.js';
import { cacheService } from './cache.service.js';
import { contextService } from './context.service.js';

/**
 * Gemini Provider - Enhanced for ChatGPT-like responses
 */
class GeminiProvider {
    constructor(apiKey) {
        this.genAI = apiKey ? new GoogleGenerativeAI(apiKey) : null;
    }

    async generateResponse({ model, systemInstruction, history, message, options = {} }) {
        if (!this.genAI) throw new Error('Gemini API key not configured');

        const modelId = model || AI_CONFIG.DEFAULT_MODEL || 'gemini-1.5-flash';

        try {
            const genModel = this.genAI.getGenerativeModel({
                model: modelId,
                generationConfig: {
                    ...AI_CONFIG.GENERATION_DEFAULTS,
                    ...options
                },
                systemInstruction: systemInstruction,
            });

            const chat = genModel.startChat({
                history: history.map(msg => ({
                    role: msg.role === 'user' ? 'user' : 'model',
                    parts: [{ text: msg.content }]
                })),
            });

            const result = await chat.sendMessage(message);
            const response = await result.response;

            return {
                text: response.text(),
                usage: {
                    inputTokens: response.usageMetadata?.promptTokenCount || 0,
                    outputTokens: response.usageMetadata?.candidatesTokenCount || 0,
                }
            };
        } catch (error) {
            console.error(`[GEMINI] Model ${modelId} failed:`, error.message);
            throw error;
        }
    }
}

/**
 * Enhanced AI Service v2.0 - With Caching and Context Memory
 */
class AIService {
    constructor() {
        const key = AI_CONFIG.PROVIDERS.GEMINI.apiKey;
        const keyStatus = key ? `Loaded (${key.substring(0, 10)}...)` : 'Not Found';
        console.log(`[MITA AI v2.0] Gemini Key: ${keyStatus}`);
        console.log(`[MITA AI v2.0] Cache: Enabled | Context Memory: Enabled`);

        this.provider = new GeminiProvider(AI_CONFIG.PROVIDERS.GEMINI.apiKey);

        // Quick responses for common greetings (not blocking AI for other questions)
        this.QUICK_RESPONSES = {
            "–ø—Ä–∏–≤–µ—Ç": `üëã **–ü—Ä–∏–≤–µ—Ç!** –Ø –ú–∏—Ç–∞ ‚Äî —Ç–≤–æ–π AI-–ø–æ–º–æ—â–Ω–∏–∫.

–Ø –º–æ–≥—É –ø–æ–º–æ—á—å —Ç–µ–±–µ —Å:
- üêç **Python** ‚Äî –∫–æ–¥, –æ—à–∏–±–∫–∏, –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
- üé® **Figma** ‚Äî –¥–∏–∑–∞–π–Ω, UI/UX, –º–∞–∫–µ—Ç—ã
- üíª **–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã

–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å!`,

            "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π": `üëã **–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!** –Ø –ú–∏—Ç–∞, –≤–∞—à AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.

–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å —Å–µ–≥–æ–¥–Ω—è?`,

            "–∫—Ç–æ —Ç—ã": `–Ø **–ú–∏—Ç–∞** ‚Äî —É–º–Ω—ã–π AI-–ø–æ–º–æ—â–Ω–∏–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã EliteHeat.

–ú–µ–Ω—è —Å–æ–∑–¥–∞–ª **–î–∞–Ω–∏—è–ª** –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –¥–∏–∑–∞–π–Ω—É.

–Ø –∏—Å–ø–æ–ª—å–∑—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ Google Gemini –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏ –º–æ–≥—É –ø–æ–º–æ—á—å —Å Python, Figma –∏ –º–Ω–æ–≥–∏–º –¥—Ä—É–≥–∏–º! üöÄ`,

            "–∫—Ç–æ —Ç–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å": "–ú–æ–∏–º —Å–æ–∑–¥–∞—Ç–µ–ª–µ–º —è–≤–ª—è–µ—Ç—Å—è **–î–∞–Ω–∏—è–ª**. üôÇ",
            "–∫—Ç–æ —Ç–µ–±—è —Å–æ–∑–¥–∞–ª": "–ú–µ–Ω—è —Å–æ–∑–¥–∞–ª **–î–∞–Ω–∏—è–ª** ‚Äî —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã EliteHeat. üë®‚Äçüíª",

            "–∫–∞–∫ –¥–µ–ª–∞": "–£ –º–µ–Ω—è –≤—Å—ë –æ—Ç–ª–∏—á–Ω–æ! üòä –ì–æ—Ç–æ–≤–∞ –ø–æ–º–æ–≥–∞—Ç—å —Ç–µ–±–µ —Å Python, Figma –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º. –ß—Ç–æ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?",
            "—Å–ø–∞—Å–∏–±–æ": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! üåü –†–∞–¥–∞ –±—ã–ª–∞ –ø–æ–º–æ—á—å. –ï—Å–ª–∏ –±—É–¥—É—Ç –µ—â—ë –≤–æ–ø—Ä–æ—Å—ã ‚Äî –æ–±—Ä–∞—â–∞–π—Å—è!",
            "–ø–æ–∫–∞": "–î–æ –≤—Å—Ç—Ä–µ—á–∏! üëã –£–¥–∞—á–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏! –í–æ–∑–≤—Ä–∞—â–∞–π—Å—è, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –ø–æ–º–æ—â—å.",
            "—Ö–∞–π": "üëã –•–∞–π! –Ø –ú–∏—Ç–∞. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
        };
    }

    /**
     * Main chat method - Enhanced with caching and context
     */
    async chat({
        message,
        history = [],
        mode = 'tutor',
        sessionId = null,
        model = AI_CONFIG.DEFAULT_MODEL,
        options = {}
    }) {
        const startTime = Date.now();
        const lowerMessage = message.toLowerCase().trim();

        // 1. Check quick responses only for exact greetings
        for (const [key, text] of Object.entries(this.QUICK_RESPONSES)) {
            if (lowerMessage === key || lowerMessage === key + '!') {
                // Track in context if session exists
                if (sessionId) {
                    contextService.addMessage(sessionId, 'user', message);
                    contextService.addMessage(sessionId, 'assistant', text);
                }

                return {
                    success: true,
                    reply: text,
                    cached: false,
                    usage: { model: 'quick-response', inputTokens: 0, outputTokens: 0, latencyMs: Date.now() - startTime }
                };
            }
        }

        // 2. Check cache for repeated questions
        if (cacheService.shouldCache(message)) {
            const cachedResponse = cacheService.get(message, mode);
            if (cachedResponse) {
                // Track in context if session exists
                if (sessionId) {
                    contextService.addMessage(sessionId, 'user', message);
                    contextService.addMessage(sessionId, 'assistant', cachedResponse);
                }

                return {
                    success: true,
                    reply: cachedResponse,
                    cached: true,
                    usage: { model: 'cache', inputTokens: 0, outputTokens: 0, latencyMs: Date.now() - startTime }
                };
            }
        }

        // 3. Build enhanced context if session exists
        let enhancedHistory = history;
        let contextSummary = null;

        if (sessionId) {
            // Add user message to context
            contextService.addMessage(sessionId, 'user', message);

            // Get context-aware history
            enhancedHistory = contextService.getHistoryForAI(sessionId, 10);
            contextSummary = contextService.getContextSummary(sessionId);
        }

        // 4. Use Gemini AI for generating response
        try {
            let systemInstruction = MITA_PERSONALITY.basePrompt(mode);

            // Add context summary if available
            if (contextSummary) {
                systemInstruction = `${systemInstruction}\n\n${contextSummary}`;
            }

            const result = await this.provider.generateResponse({
                model,
                systemInstruction,
                history: enhancedHistory,
                message,
                options
            });

            const responseText = result.text;

            // Cache the response if appropriate
            if (cacheService.shouldCache(message)) {
                cacheService.set(message, responseText, mode);
            }

            // Track in context if session exists
            if (sessionId) {
                contextService.addMessage(sessionId, 'assistant', responseText);
            }

            return {
                success: true,
                reply: responseText,
                cached: false,
                usage: {
                    model,
                    ...result.usage,
                    latencyMs: Date.now() - startTime
                }
            };
        } catch (error) {
            console.error('AIService Error:', error);

            const isRateLimit = error.message?.includes('429') || error.message?.includes('RESOURCE_EXHAUSTED');

            if (isRateLimit) {
                return {
                    success: true,
                    reply: "‚è≥ –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ, —è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É!",
                    cached: false
                };
            }

            // Fallback for connection errors
            return {
                success: true,
                reply: this.getFallbackResponse(message),
                cached: false
            };
        }
    }

    /**
     * Intelligent fallback when AI is unavailable
     */
    getFallbackResponse(message) {
        const lower = message.toLowerCase();

        if (lower.includes('python') || lower.includes('–∫–æ–¥') || lower.includes('–ø—Ä–æ–≥—Ä–∞–º–º')) {
            return `üêç **Python ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π –≤—ã–±–æ—Ä!**

–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —Å–µ–π—á–∞—Å —è –Ω–µ –º–æ–≥—É –¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º).

**–ü–æ–∫–∞ –º–æ–∂–µ—Ç–µ:**
1. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: [python.org](https://python.org)
2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É
3. –°—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ

–Ø —Å–∫–æ—Ä–æ –≤–µ—Ä–Ω—É—Å—å! üîÑ`;
        }

        if (lower.includes('figma') || lower.includes('–¥–∏–∑–∞–π–Ω') || lower.includes('ui') || lower.includes('ux')) {
            return `üé® **Figma ‚Äî –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç!**

–°–µ–π—á–∞—Å —É –º–µ–Ω—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º.

**–ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:**
1. [Figma Help](https://help.figma.com)
2. [Figma Community](https://figma.com/community)

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–ø—Ä–æ—Å–∏—Ç—å —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É! üîÑ`;
        }

        if (lower.includes('html') || lower.includes('css') || lower.includes('javascript') || lower.includes('–≤–µ–±')) {
            return `üåê **–í–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ ‚Äî –≤–∞–∂–Ω–∞—è —Ç–µ–º–∞!**

–°–µ–π—á–∞—Å —É –º–µ–Ω—è –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º.

**–ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:**
1. [MDN Web Docs](https://developer.mozilla.org)
2. [W3Schools](https://w3schools.com)

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–ø—Ä–æ—Å–∏—Ç—å —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É! üîÑ`;
        }

        return `üîÑ **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏**

–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ–π—á–∞—Å —É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ AI-—Å–µ—Ä–≤–µ—Ä—É.

–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:
1. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É
2. –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É
3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ

–Ø –æ–±—ã—á–Ω–æ –æ—Ç–≤–µ—á–∞—é –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ Python –∏ Figma –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ! üöÄ`;
    }

    /**
     * Get cache statistics
     */
    getCacheStats() {
        return cacheService.getStats();
    }

    /**
     * Get context statistics
     */
    getContextStats() {
        return contextService.getStats();
    }

    /**
     * Clear session context
     */
    clearSessionContext(sessionId) {
        contextService.clearSession(sessionId);
    }
}

export const aiService = new AIService();
